{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 卷积神经网络实践：混凝土裂缝图像分类\n",
        "\n",
        "在这个实践中，我们将学习如何使用PyTorch实现卷积神经网络(CNN)模型。我们将以混凝土裂缝图像分类为例，这是土木工程中的一个重要应用。\n",
        "\n",
        "## 1. 导入必要的库"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from PIL import Image\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. 准备数据\n",
        "\n",
        "通常，我们会使用真实的混凝土裂缝图像数据集。但为了演示目的，我们将创建一个简单的模拟数据集。在实际应用中，您需要替换这部分代码以加载和处理真实的图像数据。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_dummy_image(has_crack):\n",
        "    img = np.zeros((64, 64), dtype=np.uint8)\n",
        "    if has_crack:\n",
        "        # 添加裂缝\n",
        "        start = np.random.randint(0, 32)\n",
        "        img[start:start+32, 32] = 255\n",
        "    return Image.fromarray(img)\n",
        "\n",
        "# 创建模拟数据集\n",
        "n_samples = 1000\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for i in range(n_samples):\n",
        "    has_crack = i % 2 == 0\n",
        "    img = create_dummy_image(has_crack)\n",
        "    images.append(img)\n",
        "    labels.append(1 if has_crack else 0)\n",
        "\n",
        "# 显示一些样本图像\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    ax.imshow(images[i], cmap='gray')\n",
        "    ax.set_title(f\"Label: {'Crack' if labels[i] == 1 else 'No Crack'}\")\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. 数据预处理和加载"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CrackDataset(Dataset):\n",
        "    def __init__(self, images, labels, transform=None):\n",
        "        self.images = images\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        label = self.labels[idx]\n",
        "        \n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label\n",
        "\n",
        "# 定义数据转换\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# 划分训练集和测试集\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# 创建数据集\n",
        "train_dataset = CrackDataset(X_train, y_train, transform=transform)\n",
        "test_dataset = CrackDataset(X_test, y_test, transform=transform)\n",
        "\n",
        "# 创建数据加载器\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(f\"训练集大小: {len(train_dataset)}\")\n",
        "print(f\"测试集大小: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. 定义卷积神经网络模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class CrackCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CrackCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
        "        self.fc2 = nn.Linear(128, 2)\n",
        "        self.relu = nn.ReLU()\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 16 * 16)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# 实例化模型\n",
        "model = CrackCNN()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. 定义损失函数和优化器"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. 训练模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_epochs = 10\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for images, labels in train_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "    \n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. 评估模型"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "accuracy = 100 * correct / total\n",
        "print(f'测试集准确率: {accuracy:.2f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. 可视化一些预测结果"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def imshow(img, ax):\n",
        "    img = img / 2 + 0.5  # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    ax.imshow(npimg, cmap='gray')\n",
        "\n",
        "model.eval()\n",
        "images, labels = next(iter(test_loader))\n",
        "\n",
        "outputs = model(images.to(device))\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 6))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    imshow(images[i].squeeze(), ax)\n",
        "    # set font to red if prediction is incorrect\n",
        "    ax.set_title(f\"Pred: {'Crack' if predicted[i] == 1 else 'No Crack'}\\nTrue: {'Crack' if labels[i] == 1 else 'No Crack'}\", color='red' if predicted[i] != labels[i] else 'black')\n",
        "    ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. 总结\n",
        "\n",
        "在这个实践中，我们学习了如何使用PyTorch实现一个简单的卷积神经网络来进行混凝土裂缝图像分类。主要步骤包括:\n",
        "\n",
        "1. 准备和可视化数据\n",
        "2. 数据预处理和加载\n",
        "3. 定义CNN模型结构\n",
        "4. 选择损失函数和优化器\n",
        "5. 训练模型\n",
        "6. 评估模型性能\n",
        "7. 可视化预测结果\n",
        "\n",
        "这个例子展示了如何将深度学习应用于土木工程中的实际问题。通过这种方法，我们可以自动检测混凝土结构中的裂缝，这对于结构健康监测和维护决策都有重要意义。\n",
        "\n",
        "在实际应用中，您需要使用更大的真实数据集，可能还需要进行数据增强和更复杂的模型设计。此外，考虑到混凝土裂缝的复杂性，您可能还需要进行裂缝定位和严重程度评估等更高级的任务。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
